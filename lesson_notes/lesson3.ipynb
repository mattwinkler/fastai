{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/paperspace')\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.imports import *\n",
    "from fastai.transforms import *\n",
    "from fastai.conv_learner import *\n",
    "from fastai.model import *\n",
    "from fastai.dataset import *\n",
    "from fastai.sgdr import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set PATH = directory where dogs and cats image data lives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.conv_learner import *\n",
    "PATH = '/home/paperspace/fastai/dogscats/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image and batch sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = 224; bs = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the Resnet50 architecture to a Neural Net built using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet50 comes first:\n",
    "\n",
    "By default, all the layers except for the last few have frozen weights in the models downloaded from ImageNet.  This passes `test_name` to ImageClassifierData for future predictions.\n",
    "\n",
    "This step takes a while. . ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34ed4875868f4b2393892f16ef09052d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                     \n",
      "    0      0.042015   0.025537   0.991     \n",
      "    1      0.038854   0.026472   0.991                        \n",
      "    2      0.036191   0.023809   0.991                        \n",
      "\n",
      "CPU times: user 16min 52s, sys: 18min 58s, total: 35min 50s\n",
      "Wall time: 4min 46s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.02381]), 0.991]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfms = tfms_from_model(resnet50, sz, aug_tfms = transforms_side_on, max_zoom = 1.1)\n",
    "data = ImageClassifierData.from_paths(PATH, tfms = tfms, bs = bs, test_name = 'test1')\n",
    "learn = ConvLearner.pretrained(resnet50, data)\n",
    "\n",
    "# Three learning cycles with a learning rate of 1e-2.  No cycle length multiplication.\n",
    "% time learn.fit(1e-2, 3, cycle_len = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unfreeze layers from Resnet50 and a apply differential learning rates:\n",
    "\n",
    "`bn_freeze` means that batch normalizations won't be updated. Don't need to do that if images largely conform to the Resnet architecture and are appropriate size (200 - 500px)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c133651e6b0847018431fb601515058c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                     \n",
      "    0      0.018844   0.023606   0.991     \n",
      "\n",
      "CPU times: user 7min 7s, sys: 6min 37s, total: 13min 45s\n",
      "Wall time: 3min 32s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.02361]), 0.991]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.bn_freeze(True) # sets the batch normalization to **not** be updated at each iteration. \n",
    "% time learn.fit([1e-5, 1e-4, 1e-2], 1, cycle_len = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get predictions on validation set and score the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 10.5 Âµs\n",
      "                                             \r"
     ]
    }
   ],
   "source": [
    "% time \n",
    "log_preds, y = learn.TTA() # running with test time augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = np.exp(log_preds) # e^ on log_preds to translate them to probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resolve mismatch between log_preds formatting and y:\n",
    "\n",
    "TTA does some image transformation when making the predictions, so it's changing the shape of the ouptut array that can be averaged together before scoring against y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000,), (5, 2000, 2))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at y and log_preds shapes:\n",
    "y.shape, probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looks like log_preds contains a set of 5 prediction arrays from the test time augmentation above.\n",
    "probs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average each set of predictions together over the first axis, which differentiates the prediction sets:\n",
    "probs = np.mean(probs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99997, 0.00003],\n",
       "       [0.99955, 0.00045],\n",
       "       [0.99998, 0.00002],\n",
       "       [0.99951, 0.00049],\n",
       "       [0.99998, 0.00002]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[0:5] # array of probabilities for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert probabilities to binary predictions on the target.  Second column represents class 1:\n",
    "preds = probs[:, 1] > 0.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.016761740747447938, 0.994)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.log_loss(y, probs), np.mean(preds == y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the above to an alternative built using Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching package metadata ...........\n",
      "Solving package specifications: .\n",
      "\n",
      "# All requested packages already installed.\n",
      "# packages in environment at /home/paperspace/anaconda3/envs/fastai:\n",
      "#\n",
      "keras                     2.1.5                    py36_0  \n",
      "tensorflow-gpu            1.7.0                         0  \n"
     ]
    }
   ],
   "source": [
    "# install Tensorflow backend:\n",
    "# the --prefix ensures that what's installed is usable from the current notebook.\n",
    "#!conda install --yes --prefix {sys.prefix} tensorflow-gpu keras \n",
    "\n",
    "# Don't run like this: !conda install --yes numpy\n",
    "\n",
    "# More info: https://jakevdp.github.io/blog/2017/12/05/installing-python-packages-from-jupyter/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.applications import ResNet50\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = f'{PATH}train'\n",
    "validation_data_dir = f'{PATH}valid'\n",
    "sz=224\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define data generators:\n",
    "* augmentation\n",
    "* normalization\n",
    "* specify image size and mini-batch size for the image generator.  \n",
    "* do the same thing for the validation_generator.  Be sure not to shuffle here because you need to track the prediction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1. / 255, \n",
    "                                   shear_range = 0.2, \n",
    "                                   zoom_range = 0.2, \n",
    "                                   horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                    target_size=(sz, sz),\n",
    "                                                    batch_size=batch_size, \n",
    "                                                    # could set class_mode = 'categorical for a multiclass problem\n",
    "                                                    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = test_datagen.flow_from_directory(validation_data_dir,\n",
    "                                                        shuffle=False,\n",
    "                                                        target_size=(sz, sz),\n",
    "                                                        batch_size=batch_size, \n",
    "                                                        class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make the base model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras doesn't include ResNet34, so use ResNet50 to compare the same models\n",
    "\n",
    "base_model = ResNet50(weights = 'imagenet', include_top = False)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation = 'relu')(x)\n",
    "predictions = Dense(1, activation = 'sigmoid')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loop through and freeze the desired layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model:\n",
    "model = Model(inputs = base_model.input, outputs = predictions)\n",
    "\n",
    "for layer in base_model.layers: \n",
    "    layer.trainable = False\n",
    "\n",
    "# Pass optimizer, loss function and evaluation metric:\n",
    "model.compile(optimizer = 'rmsprop', \n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the model:\n",
    "* size per epoch\n",
    "* number of workers\n",
    "* batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    }
   ],
   "source": [
    "\"\"\"%%time\n",
    "model.fit_generator(train_generator, \n",
    "                     train_generator.n / batch_size, \n",
    "                    epochs = 3, \n",
    "                    workers = 4,\n",
    "                    validation_data = validation_generator, \n",
    "                    validation_steps = validation_generator.n / batch_size)\n",
    "\"\"\"          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect model layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrain some of the layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split_at = 140\n",
    "#for layer in model.layers[:split_at]:\n",
    "#    layer.trainable = False\n",
    "\n",
    "#for layer in model.layers[split_at:]:\n",
    "#    layer.trainable = True\n",
    "    \n",
    "#model.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
